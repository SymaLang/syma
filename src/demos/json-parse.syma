:module multiline
  {Module JSON
   {Import Core/String as S open}
   {Export}
   {Rules
     {R JSONParse {JSONParse s_} Tokenize(Core/String/SplitToChars(Unescape(s_))) :guard IsStr(s_)}
     {R Tokenize {Tokenize {Core/String/Chars chars...}} {TokenizerState Start {Tokens} Core/String/Chars(chars...)}}

     ; Intermediate tokenizer state: {TokenizerState Start|Processing|End {Focus a_ b_} {Tokens} {Core/String/Chars}}
     ; Where Token is {TOKObjOpen} | {TOKSTR chars...} | {TOKCOLON} | ...

     {R Tokenize/Start {TokenizerState Start {Tokens} Core/String/Chars(a_, b_, chars...)} {TokenizerState Processing Default {Focus a_ b_} {Tokens} Core/String/Chars(chars...)}}
     {R Tokenize/End   {TokenizerState End {Tokens tok...}} {Tokens tok...}}

    ; Focus leaf states — focusing on one char
    {R Tokenize/Mode/Number/End/Leaf1/NumEnd
      {TokenizerState Processing Number/Int {Focus a_} {Tokens tok...} {Core/String/Chars}}
      {TokenizerState Processing Default {Focus a_} {Tokens tok...} {Core/String/Chars}}
      :guard Not(IsValidIntCont(a_))
    }

    {R Tokenize/Mode/String/End/Leaf1
      {TokenizerState Processing Default {Focus a_} {Tokens tok...} {Core/String/Chars}}
      {TokenizerState End {Tokens tok... {TOKRCURLY} }}
      :guard Eq(a_, "}")
    }

     ; Focus leaf states — still focusing on two chars
    {R Tokenize/Mode/String/End/Leaf2
      {TokenizerState Processing String {Focus a_ b_} {Tokens tok... {TOKSTR str...}} {Core/String/Chars}}
      {TokenizerState Processing Default {Focus b_} {Tokens tok... {TOKSTR str...} } {Core/String/Chars}}
      :guard Eq(a_, Unescape("\""))
    }

    {R Tokenize/Mode/Default/Leaf2/Num
    {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} {Core/String/Chars}}
    {TokenizerState Processing Number/Int {Focus b_} {Tokens tok... {TOKNUM a_}} {Core/String/Chars}}
    :guard Or(Eq(a_, "-"), IsDigit(a_))}

     {R Tokenize/Mode/Default/Object {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} Core/String/Chars(next_, chars...)} {TokenizerState Processing Default {Focus b_ next_} {Tokens tok... {TOKLCURLY} } Core/String/Chars(chars...)} :guard Eq(a_, "{")}

     ; String switches tokenizer state to string
     {R Tokenize/Mode/Default/String {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} Core/String/Chars(next_, chars...)} {TokenizerState Processing String {Focus b_ next_} {Tokens tok... {TOKSTR} } Core/String/Chars(chars...)} :guard Eq(a_, Unescape("\""))}

    ; Digit or "-" switches tokenizer state to number
    {R Tokenize/Mode/Default/Number
      {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} Core/String/Chars(next_, chars...)}
      {TokenizerState Processing Number/Int {Focus b_ next_} {Tokens tok... {TOKNUM a_} } Core/String/Chars(chars...)} :guard Or(Eq(a_, "-"), IsDigit(a_))}

     ; Basics
     {R Tokenize/Mode/Default/Colon {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} Core/String/Chars(next_, chars...)} {TokenizerState Processing Default {Focus b_ next_} {Tokens tok... {TOKCOLON} } Core/String/Chars(chars...)} :guard Eq(a_, ":")}

     {R Tokenize/Mode/Default/Comma {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} Core/String/Chars(next_, chars...)} {TokenizerState Processing Default {Focus b_ next_} {Tokens tok... {TOKCOMMA} } Core/String/Chars(chars...)} :guard Eq(a_, ",")}

     ; Eating spaces
     {R Tokenize/Mode/Default/EatSpaces {TokenizerState Processing Default {Focus a_ b_} {Tokens tok...} Core/String/Chars(next_, chars...)} {TokenizerState Processing Default {Focus b_ next_} {Tokens tok...} Core/String/Chars(chars...)} :guard Eq(a_, " ")}

     ; String processing

    {R Tokenize/Mode/String/Cont
    {TokenizerState Processing String {Focus a_ b_} {Tokens tok... {TOKSTR str...}} Core/String/Chars(next_, chars...)}
    {TokenizerState Processing String {Focus b_ next_} {Tokens tok... {TOKSTR Concat(str..., a_)} } Core/String/Chars(chars...)}
    :guard Neq(a_, Unescape("\""))}

    {R Tokenize/Mode/String/End {TokenizerState Processing String {Focus a_ b_} {Tokens tok... {TOKSTR str...}} Core/String/Chars(next_, chars...)} {TokenizerState Processing Default {Focus b_ next_} {Tokens tok... {TOKSTR str...} } Core/String/Chars(chars...)} :guard Eq(a_, Unescape("\""))}

    ; Number processing
    {R Tokenize/Mode/Num/Int/End
      {TokenizerState Processing Number/Int {Focus a_ b_} {Tokens tok... {TOKNUM num...}} {Core/String/Chars next_ chars...}}
      {TokenizerState Processing Default {Focus b_ next_} {Tokens tok... {TOKNUM num...}} {Core/String/Chars chars...}}
      :guard Not(IsValidIntCont(a_))
    }

    ; Helpers
    {R IsDigit {IsDigit c_} Neq({IndexOf "0123456789" c_}, -1)}
    {R IsValidIntCont {IsValidIntCont c_} Neq({IndexOf "0123456789" c_}, -1) }
   }


  }
:end

:import JSON

//

JSONParse("{\"Hello\":    \"world\", \"Spoordo\": 3, \"someNum\": 5, \"pazaak\": {}}")